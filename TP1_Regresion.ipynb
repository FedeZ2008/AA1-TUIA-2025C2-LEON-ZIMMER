{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ab3108",
   "metadata": {},
   "source": [
    "# TP1 - Regresión\n",
    "Notebook inicial para el trabajo práctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b273a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler   # u otros scalers\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27b8c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>date</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        key                           date  fare_amount  \\\n",
       "0  24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1  27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2  44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3  25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4  17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "\n",
       "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Carga de datos. Se carga el dataset que contiene los viajes de taxi.\n",
    "file_path= 'uber_fares.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# visualizacion de algunos datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df1f21",
   "metadata": {},
   "source": [
    "#### Contexto  \n",
    "El proyecto trata sobre **Uber Inc.**, la compañía de taxis más grande del mundo. En este trabajo, nuestro objetivo es **predecir la tarifa de futuros viajes**.  \n",
    "\n",
    "Uber brinda servicio a millones de clientes cada día, por lo que gestionar adecuadamente sus datos es clave para desarrollar nuevas estrategias de negocio y obtener mejores resultados.  \n",
    "\n",
    "### Variables del conjunto de datos  \n",
    "\n",
    "**Variables explicativas:**  \n",
    "- **key**: identificador único de cada viaje.  \n",
    "- **pickup_datetime**: fecha y hora en que se inició el viaje.  \n",
    "- **passenger_count**: cantidad de pasajeros en el vehículo (dato ingresado por el conductor).  \n",
    "- **pickup_longitude**: longitud del punto de inicio del viaje.  \n",
    "- **pickup_latitude**: latitud del punto de inicio del viaje.  \n",
    "- **dropoff_longitude**: longitud del punto de destino.  \n",
    "- **dropoff_latitude**: latitud del punto de destino.  \n",
    "\n",
    "**Variable objetivo (target):**  \n",
    "- **fare_amount**: costo del viaje en dólares.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b83a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'date', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Análisis descriptivo de las variables\n",
    "# Comentario: Se realiza un análisis inicial para comprender el comportamiento de cada variable.\n",
    "# - Descripción estadística (df.describe())\n",
    "# - Visualización de valores únicos y rangos\n",
    "# - Crear variables como distancia del viaje, horario (puede ser en formato como explicaron en clase),\n",
    "#   día de la semana, semana del año, ambas podrían ser cualitativas ordinales.\n",
    "# - Identificación de valores atípicos (outliers) y datos faltantes (missing values)d\n",
    "\n",
    "# Columnas, ¿cuáles son variables numéricas y cuales variables categóricas?\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d02190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   key                200000 non-null  int64  \n",
      " 1   date               200000 non-null  object \n",
      " 2   fare_amount        200000 non-null  float64\n",
      " 3   pickup_datetime    200000 non-null  object \n",
      " 4   pickup_longitude   200000 non-null  float64\n",
      " 5   pickup_latitude    200000 non-null  float64\n",
      " 6   dropoff_longitude  199999 non-null  float64\n",
      " 7   dropoff_latitude   199999 non-null  float64\n",
      " 8   passenger_count    200000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748edcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Análisis y tratamiento de datos faltantes\n",
    "# Comentario: Se identifican valores faltantes y se decide cómo tratarlos (eliminación, imputación, etc.).\n",
    "# - df.isnull().sum()\n",
    "# - Justificación de la decisión tomada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Análisis y tratamiento de datos atípicos (outliers)\n",
    "# Comentario: Se detectan y tratan valores atípicos en las variables numéricas.\n",
    "# - Visualización con boxplots\n",
    "# - Decisión sobre el tratamiento (eliminación, ajuste, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualización de datos\n",
    "# Comentario: Se grafican histogramas y scatterplots para analizar la distribución y relaciones entre variables.\n",
    "# - Histograma de cada variable\n",
    "# - Scatterplots entre variables relevantes\n",
    "# - Diagramas de caja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d55107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Codificación de variables categóricas (si corresponde)\n",
    "# Comentario: Se codifican variables categóricas para su uso en modelos (OneHotEncoder, LabelEncoder, etc.).\n",
    "# - Ejemplo: df['var'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07709af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Matriz de correlación\n",
    "# Comentario: Se calcula la matriz de correlación para analizar dependencias entre variables.\n",
    "# - sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b78becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Estandarización o escalado de datos\n",
    "# Comentario: Se aplican técnicas de escalado para mejorar el desempeño de los modelos.\n",
    "# - StandardScaler, MinMaxScaler, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37740681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. División de datos: Train-Test (y opcionalmente Validación)\n",
    "# Comentario: Se divide el conjunto de datos en entrenamiento y prueba.\n",
    "# - from sklearn.model_selection import train_test_split\n",
    "# - X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='fare_amount'), df['fare_amount'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38994b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e68b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Implementación de modelos de regresión\n",
    "# 11.a. Regresión lineal múltiple (LinearRegression)\n",
    "# Comentario: Se ajusta el modelo base de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c59ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.b. Métodos de gradiente descendente (SGDRegressor, otros)\n",
    "# Comentario: Se prueban diferentes variantes de gradiente descendente.\n",
    "# - Se grafican errores vs iteraciones (loss vs epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.c. Métodos de regularización (Lasso, Ridge, Elastic Net)\n",
    "# Comentario: Se aplican modelos con regularización y se varía el coeficiente.\n",
    "# - Se comparan métricas para distintos valores de alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Evaluación de modelos: métricas de regresión\n",
    "# Comentario: Se calculan las métricas elegidas para train y test (R2, MSE, RMSE, MAE, MAPE).\n",
    "# - Justificación de las métricas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Gráficos de residuos\n",
    "# Comentario: Se grafican los residuos para analizar el ajuste de los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d88767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Análisis de fitting y conclusiones intermedias\n",
    "# Comentario: Se analiza el fitting del modelo y se discuten los efectos de la regularización y gradiente descendente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Optimización y comparación de hiperparámetros\n",
    "# Comentario: Se varían los hiperparámetros y se observa el efecto en el desempeño del modelo.\n",
    "# - GridSearchCV, RandomizedSearchCV, o análisis manual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Comparación de modelos\n",
    "# Comentario: Se compara el desempeño de los distintos modelos y se selecciona el mejor.\n",
    "# - Justificación de la métrica de comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Conclusiones finales\n",
    "# Comentario: Se redacta una conclusión sobre el trabajo realizado, principales hallazgos y aprendizajes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
